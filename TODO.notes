# Pipelines Repo
- Add protection to the release branch
I don't think we want to do this - it's up to the project to decide how to manage
their branches.

# MHKDR Integration
Need a script to create a dataset in MHKDR and then set up a DataSync resource to keep 
the tsdat output bucket in sync with the MHKDR dataset bucket.  
DataSync can be created via CDK or boto3 (TBD). 

# Lambda Logging
- Fix lambda logging - it appears our DelayedJSONStreamHandler isn't working like we 
want.  See if we can override this in the lambda container so we aren't 
creating a cloudwatch entry for every log statement in the code.

# Code Build webhook filters  
See if we can change the type of code build object that is created in the stack (e.g.,
use code build only instead of code pipeline) so that we can set webhook filters to trigger
the build on tagged release instead of push to branch.

# Let users override storage.yaml file
Users need to specify the storage yaml path in aws template and the corresponding
storage file in the pipelines repo. Then if specified build will replace the pipelines
storage with the aws storage.

# Add cloudwatch alarms for the lambda functions if there are errors in the log


# Make sure that input_bucket_path can take wildcard patterns
1. In lambda fn, is passed in as a Prefix parameter to paginator.paginate method in boto3
   when looking up files.
   - This can't have wildcards in it, so we would need to get the recently
   modified raw files from the folder in the event trigger instead
   of directly using the folder path from the config file.

2. In build, it is used in the filter rules object when calling 
   s3_client.put_bucket_notification_configuration
   "FilterRules": [
            {"Name": "prefix", "Value": subpath},
   ]

For cron triggers, we have to know the specific folder to run, 
not a wildcard pattern.

AWS does not let you use wildcards.  We will need to make the
input_bucket_path in the configs be a list instead of a single value. 

root/humboldt/humboldt.buoy_z05-imu.00